{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "This script loads the object detection model and detects products, design features of displays and shelves. The detected objects are saved in an excel-file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection_sabine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_wsp_path = os.environ.get('CAPSTONE_PATH')+'/TensorFlow/workspace/training_products_shelf/'\n",
    "annotations_path = tf_wsp_path+'annotations'\n",
    "config_path = tf_wsp_path+'models/my_ssd_resnet50_v1_fpn/pipeline.config'\n",
    "ckpt_path = tf_wsp_path+'models/my_ssd_resnet50_v1_fpn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "First, we load the pipeline config and build a detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(config_path)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we restore the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(ckpt_path, 'ckpt-26')).expect_partial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(annotations_path+'/label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Detected Objects\n",
    "\n",
    "First, we save an image with one or all detected objects as image_np_with_detections.npy. Second, we plot the saved numpy array in the notebook shelf_analysis.plot.ipynb. We save the numpy array and plot in a separate notebook because the model_builder causes matplotlib not to plot in the same notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_np_with_all_detections('images/2021/new_label/shop21.jpg', detection_model, category_index)\n",
    "#save_image_np_with_one_detection('images/2021/new_label/shop1.jpg', detection_model, category_index, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow to Excel: Sum of Objects\n",
    "\n",
    "This part detects all objects in the images, and saves the number of displays, number of detected objects for each category as well as the number of shelves with the products of interest and the maximum number of products of interest on a shelf to an excel file.\n",
    "\n",
    "First, I define a function that determines on which shelf a product is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shelf_number(product_box, a_shelf_df):\n",
    "    # calculate intersection with each shelf box\n",
    "    intersection_ls = []\n",
    "    product_box_area = (product_box[1] - product_box[0])*(product_box[3] - product_box[2])\n",
    "    for shelf_row, shelf in a_shelf_df.iterrows():\n",
    "        # coordinates of intersection box\n",
    "        xmin = max(product_box[0], shelf['xmin'])\n",
    "        xmax = min(product_box[1], shelf['xmax'])\n",
    "        ymin = max(product_box[2], shelf['ymin'])\n",
    "        ymax = min(product_box[3], shelf['ymax'])\n",
    "\n",
    "        intersection_ls.append(max(xmax - xmin, 0.0)*max(ymax - ymin, 0.0))\n",
    "\n",
    "    if intersection_ls == []: # images without shelves\n",
    "        return np.nan\n",
    "    elif max(intersection_ls) == 0: # images with shelves but relevant products not on shelves\n",
    "        return np.nan\n",
    "    else:\n",
    "        max_intersection = max(intersection_ls)\n",
    "        if max_intersection > 0.7*product_box_area:\n",
    "            return intersection_ls.index(max_intersection)\n",
    "        else:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for jpg_file in os.listdir('images/2021/new_label'):\n",
    "    file_path = os.path.join('images/2021/new_label', jpg_file)\n",
    "    all_detections = detection_from_jpg(file_path, detection_model)\n",
    "    detections = detection_selection(all_detections, 0.3) # selection of detections with a score above 0.3\n",
    "\n",
    "    # number of displays (determined by presence of a certain design feature on top of shelf)\n",
    "    ymax_ls = [obj[2] for obj in detections['detection_boxes']] # y_max of all detected objects (y=0 is upper left)\n",
    "    ymax_main_design = [ymax_ls[idx] for idx in np.where(detections['detection_classes'] == 2)[0]] # y_max of this design feature\n",
    "    ymax_avg = sum(ymax_ls) / len(ymax_ls)  # average y_max of all detected objects\n",
    "    nr_displays = sum(ymax_main_design < ymax_avg)  # number of times the design feature shows up above the other detected objects\n",
    "\n",
    "    # add how many products and design features (different categories) were detected\n",
    "    values_to_add = {'displays': nr_displays}\n",
    "    for idx, category in category_index.items():\n",
    "        if idx in (1, 2): # first two classes are products\n",
    "            values_to_add[category['name']] = sum(detections['detection_classes'] == (idx - 1)) # number of detections\n",
    "        if idx in (3, 4, 5, 6): # other classes are design features showing up either on top or bottom of shelf\n",
    "            ymax_class = [ymax_ls[idx] for idx in np.where(detections['detection_classes'] == (idx - 1))[0]]\n",
    "            nr_on_top = sum(ymax_class < ymax_avg)\n",
    "            nr_on_bottom = sum(ymax_class > ymax_avg)\n",
    "            values_to_add['top_' + category['name']] = nr_on_top\n",
    "            values_to_add['bottom_' + category['name']] = nr_on_bottom\n",
    "        if idx == 7:\n",
    "            values_to_add[category['name']] = sum(detections['detection_classes'] == (idx - 1)) # number of detections\n",
    "\n",
    "    # add number of shelves and maximum number of products on a shelf\n",
    "    image_df = pd.DataFrame(detections['detection_boxes'], columns=['ymin', 'xmin', 'ymax', 'xmax'])\n",
    "    image_df['object'] = detections['detection_classes']\n",
    "    product_df = image_df[image_df['object'].isin([0,1])] # dataframe with product bounding boxes as rows\n",
    "    shelf_df = image_df[image_df['object'] == 6] # dataframe with shelf bounding boxes as rows\n",
    "    product_df['shelf_nr'] = product_df[['xmin', 'xmax', 'ymin', 'ymax']].apply(lambda product: shelf_number(product, shelf_df), axis=1, result_type = 'expand')\n",
    "    values_to_add['nr_stacked_shelves'] = len(product_df['shelf_nr'].dropna().unique())\n",
    "    values_to_add['nr_products_without_shelf'] = product_df[product_df['shelf_nr'].isnull()]['object'].count()\n",
    "    nr_products_on_shelves_df = product_df.groupby('shelf_nr')['object'].count()\n",
    "    if product_df['shelf_nr'].isnull().all():\n",
    "        values_to_add['max_nr_products_on_shelf'] = np.nan\n",
    "    else:\n",
    "        values_to_add['max_nr_products_on_shelf'] = max(product_df.groupby('shelf_nr')['object'].count())\n",
    "\n",
    "    img_to_add = pd.Series(values_to_add, name=jpg_file[:-4])\n",
    "    df = df.append(img_to_add)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('images/2021/tables/detected_objects.xlsx')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f8cd1e5a3c93583abf4fcce1d11fad3cebb9f76000d0813f04fcdcdb8b58a8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
